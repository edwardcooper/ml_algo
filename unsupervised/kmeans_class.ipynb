{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "class Kmeans_img:\n",
    "    \"\"\"\n",
    "    Implement a simple Kmeans algorithm to compress the color values in a image.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    n_clusters: int, optional, default: 8\n",
    "        The number of clusters to form as well as the number of\n",
    "        centroids to generate.\n",
    "\n",
    "    max_iter: int, default: 100\n",
    "        Maximum number of iterations of the k-means algorithm for a\n",
    "        single run.\n",
    "    init: {'k-means++', 'random' }\n",
    "        Method for initialization, defaults to 'random'. Not implemented kmeans++ yet. \n",
    "    n_init: int, default: 1\n",
    "        Number of times the algorithm will run.\n",
    "        It will return the model with minimum total within cluster variance.\n",
    "    seed: int, default: 7\n",
    "        The seed for randomizing the cluster centers. \n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    cluster_centers_ : array, [n_clusters, n_features]\n",
    "        Coordinates of cluster centers. If the algorithm stops before fully\n",
    "        converging (see ``tol`` and ``max_iter``), these will not be\n",
    "        consistent with ``labels_``.\n",
    "\n",
    "    labels_ :\n",
    "        Labels of each point\n",
    "\n",
    "    tot_cluster_vars_ : float\n",
    "        Sum of squared distances of samples to their closest cluster center.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_clusters, max_iter = 100, tol=10**(-5), init = \"random\", n_init = 1,seed=7):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.tol= tol\n",
    "        self.init = init\n",
    "        self.n_init = n_init\n",
    "        self.seed = seed\n",
    "        \n",
    "       \n",
    "    # initialize the cluster centers with random method\n",
    "\n",
    "    def _init_cluster_centers_random(self, data):\n",
    "        init_cluster_centers = pd.DataFrame(np.random.randint(data.min().min(),data.max().max()\n",
    "                                                              ,size=(self.n_clusters, data.shape[1]))\n",
    "                                            ,index= range(self.n_clusters),columns = data.columns)\n",
    "        self.cluster_centers_ = init_cluster_centers\n",
    "        return self.cluster_centers_\n",
    "        \n",
    "\n",
    "\n",
    "    def _kmeans_distance(self,data):\n",
    "        # initialize the data frame to be all zeros to hold the distance value.\n",
    "        # each row is the cluster number, each column is the distance of each data point to the centroid.\n",
    "        distance_df = pd.DataFrame(index=range(self.n_clusters),columns= data.index)\n",
    "        distance_df = distance_df.fillna(0)\n",
    "\n",
    "        # assign the value of L2 norm distance to the centroid to each row of the distance_df\n",
    "        for i in range(self.cluster_centers_.shape[0]):\n",
    "            distance_df.iloc[i] = np.square(data-self.cluster_centers_.iloc[i]).sum(axis=1)\n",
    "\n",
    "        # return the distance dataframe\n",
    "        return distance_df\n",
    "\n",
    "    def _kmeans_iter(self, data):\n",
    "        # calculate the distance matrix\n",
    "        distance_dataframe = self._kmeans_distance(data)\n",
    "\n",
    "        # calculate the current new cluster assignments.\n",
    "        new_cluster_assignment = [0]*data.shape[0]\n",
    "        for index in range(len(new_cluster_assignment)):\n",
    "            new_cluster_assignment[index] = distance_dataframe.iloc[:,index].idxmin()\n",
    "        # finished with cluster assignment, the cluster labels are now in a list.\n",
    "\n",
    "        # initialize the dataframe to store new centroid positions.\n",
    "        new_centroid = pd.DataFrame(index= range(self.n_clusters),columns = data.columns)\n",
    "        \n",
    "        # initialize a list to store the within cluster variance to measure if the cluster converges.\n",
    "        new_centroid_variance = [0]*self.n_clusters\n",
    "\n",
    "        # iterate through all possible cluster number, and calculates the new centroid positions using the mean.\n",
    "        for cluster_value in range(self.n_clusters):\n",
    "            # get the index for new cluster assignment.\n",
    "            cluster_data_index = [new_cluster_value_index for new_cluster_value_index,new_cluster_value in enumerate(new_cluster_assignment) if new_cluster_value == cluster_value]\n",
    "            # get the data belonging to cluster \"cluster_value\"\n",
    "            cluster_data = data.iloc[cluster_data_index]\n",
    "            # calculate the centroid position using the mean for each feature.\n",
    "            new_centroid_position = cluster_data.mean(axis=0)\n",
    "            # calculate the within-cluster variance.\n",
    "            new_centroid_variance[cluster_value] = cluster_data.var(axis = 0).sum(axis = 0)\n",
    "            # assign this value to the value for the new_centroid positions.\n",
    "            new_centroid.iloc[cluster_value] = new_centroid_position\n",
    "            \n",
    "        # assign the new cluster centers, total cluster variance and new cluster assignments\n",
    "        self.tot_cluster_vars_ = sum(new_centroid_variance)\n",
    "        self.cluster_centers_ = new_centroid\n",
    "        self.labels_ = new_cluster_assignment\n",
    "        \n",
    "        return self.tot_cluster_vars_, new_centroid\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self,data):\n",
    "        # initialize the position with some random value.\n",
    "        np.random.seed(self.seed)\n",
    "        self._init_cluster_centers_random(data)\n",
    "\n",
    "        for i in tqdm(range(self.max_iter)):\n",
    "            # create a copy of the current centroid positions\n",
    "            old_centroids_positions = self.cluster_centers_.copy()\n",
    "            # do one iteration of the kmeans algorithm and return the variance of the centroids and new centroid positions.\n",
    "            new_centroids_variances, new_positions = self._kmeans_iter(data)\n",
    "\n",
    "\n",
    "            # test to see if the new position contains any NA values.\n",
    "            # if it contains NA values then you need to re-initialize the centroid positions.\n",
    "            if new_positions.isnull().sum().sum() !=0:\n",
    "                np.random.seed(self.seed+i)\n",
    "                self.cluster_centers_= self._init_cluster_centers_random(data)\n",
    "\n",
    "\n",
    "            # calculate the squared differences in the cnetroid position change after one iterations.\n",
    "            positions_sq_diff = np.square(old_centroids_positions-new_positions).sum(axis=0).sum()\n",
    "\n",
    "            # if the change in the squared difference is smaller than the tol value then the iteration is stopped.\n",
    "            if positions_sq_diff < self.tol:\n",
    "                break\n",
    "\n",
    "\n",
    "        return self.cluster_centers_\n",
    "    \n",
    "    def predict(self, newdata):\n",
    "        # calculate the distance matrix \n",
    "        distance_dataframe = self._kmeans_distance(newdata)\n",
    "    \n",
    "        # calculate the current new cluster assignments.\n",
    "        new_cluster_assignment = [0]*newdata.shape[0]\n",
    "        for index in range(len(new_cluster_assignment)):\n",
    "        \n",
    "            new_cluster_assignment[index] = distance_dataframe.iloc[:,index].idxmin()\n",
    "    \n",
    "        return new_cluster_assignment\n",
    "    \n",
    "    def transform(self, newdata):\n",
    "        # generate the cluster labels from the distance metric.\n",
    "        cluster_labels = self.predict(newdata)\n",
    "    \n",
    "        # initialize new dataframe for storing the compressed data\n",
    "        new_compressed_img_data = pd.DataFrame(index= range(newdata.shape[0]),columns = newdata.columns)\n",
    "        for index, cluster_label in enumerate(cluster_labels):\n",
    "             new_compressed_img_data.iloc[index] = self.cluster_centers_.iloc[cluster_label]\n",
    "    \n",
    "        return new_compressed_img_data\n",
    "    \n",
    "        \n",
    "    @staticmethod\n",
    "    def read_tiff(path):\n",
    "        # read the tiff image data\n",
    "        im = Image.open(path)\n",
    "        # convert it into a numpy array\n",
    "        image = np.array(im)\n",
    "        # return the numpy array for furthur processing.\n",
    "        return image\n",
    "    @staticmethod\n",
    "    def from_np_to_pd(data):\n",
    "        # reshaped the input data\n",
    "        data_reshaped = data.reshape(data.shape[0]*data.shape[1],3)\n",
    "        # convert it to a pandas dataframe\n",
    "        reshaped_df = pd.DataFrame(data_reshaped)\n",
    "        \n",
    "        return reshaped_df\n",
    "    @staticmethod\n",
    "    def from_pd_to_img(data,img):\n",
    "        # get the data values from pandas dataframe\n",
    "        data = data.values\n",
    "        # reshape the numpy array into original image format. \n",
    "        data_reshaped = data.reshape(img.shape[0],img.shape[1],3)\n",
    "        # convert to unit8 data type\n",
    "        img_unit8 = np.uint8(data_reshaped)\n",
    "        # convert to image from numpy array\n",
    "        img = Image.fromarray(img_unit8)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data2 = pd.DataFrame([[-1,1],[1,-1],[1.01,-1.01]\n",
    "                           ,[-1.01,1.01],[1.02,-1.02]\n",
    "                           ,[-1.02,1.02],[1.03,-1.03]\n",
    "                           ,[-1.03,1.03]], columns = [\"f1\",'f2'])\n",
    "\n",
    "\n",
    "test_data2 = pd.DataFrame([[-1.2,1.2],[1.2,-1.2]], columns = [\"f1\",'f2'])\n",
    "\n",
    "\n",
    "\n",
    "train_data3 = pd.DataFrame([[-1,1,-1],[1,-1,1]\n",
    "                           ,[1.01,-1.01,1.01]\n",
    "                           ,[-1.01,1.01,-1.01]\n",
    "                           ,[1.02,-1.02,1.02]\n",
    "                           ,[-1.02,1.02,-1.02]\n",
    "                           ,[1.2,-1.2,1.2]\n",
    "                           ,[-1.2,1.2,-1.2]], columns = [\"f1\",'f2','f3'])\n",
    "\n",
    "\n",
    "test_data3 = pd.DataFrame([[-1.3,1.3,-1.3],[1.3,-1.3,1.3]\n",
    "                          ], columns = [\"f1\",'f2','f3'])\n",
    "\n",
    "kmeans_2 = Kmeans_img(n_clusters = 2)\n",
    "kmeans_2.fit(train_data2)\n",
    "kmeans_2.predict(test_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_3 = Kmeans_img(n_clusters = 2)\n",
    "kmeans_3.fit(train_data3)\n",
    "kmeans_3.predict(test_data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the kmeans algorithm to the image data for vector quantization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the tiff data and convert it into a format that can be processed by kmeans.\n",
    "image_np = Kmeans_img.read_tiff(\"./peppers.tiff\")\n",
    "\n",
    "image_df = Kmeans_img.from_np_to_pd(image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/500 [00:08<33:09,  3.99s/it]"
     ]
    }
   ],
   "source": [
    "kmeans_img = Kmeans_img(n_clusters = 16, max_iter=500)\n",
    "\n",
    "kmeans_img.fit(image_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_img_df = kmeans_img.transform(image_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kmeans_img.from_pd_to_img(compressed_img_df,image_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
